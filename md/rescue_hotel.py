import os, requests, re, concurrent.futures
from urllib.parse import urlparse

# é…ç½®
TIMEOUT = 2
MAX_WORKERS = 60 # GitHub Actions ç¯å¢ƒå»ºè®®å¹¶å‘æ•°

def is_valid_ip(ip_str):
    """æ­£åˆ™æ ¡éªŒï¼šç¡®ä¿åªæŠ¢æ•‘ IP:Port æ ¼å¼"""
    pattern = r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:[0-9]+$'
    return bool(re.match(pattern, ip_str))

def check_url(url):
    try:
        r = requests.get(url, timeout=TIMEOUT, stream=True)
        return True if r.status_code == 200 else False
    except: return False

def main():
    if not os.path.exists("dead_tasks.txt"):
        print("âš ï¸ æœªå‘ç°å¾…æŠ¢æ•‘ä»»åŠ¡ dead_tasks.txt")
        return
    
    with open("dead_tasks.txt", 'r', encoding='utf-8') as f:
        # æŒ‰åŒæ¢è¡Œç¬¦åˆ†å‰²ç½‘æ®µå—
        blocks = [b.strip() for b in f.read().split('\n\n') if b.strip()]
    
    # è¿‡æ»¤æ‰é IP æ ¼å¼çš„å—
    valid_blocks = []
    for b in blocks:
        header = b.split('\n')[0].split(',')[0]
        if is_valid_ip(header):
            valid_blocks.append(b)
    
    total_blocks = len(valid_blocks)
    if total_blocks == 0:
        print("ğŸ“Š å¾…æŠ¢æ•‘æ¸…å•ä¸­æ²¡æœ‰ç¬¦åˆæ ¼å¼çš„ IP æ®µï¼Œè·³è¿‡æŠ¢æ•‘ã€‚")
        return

    print(f"ğŸš‘ å‡†å¤‡æŠ¢æ•‘ {total_blocks} ä¸ªå¤±æ•ˆç½‘æ®µ...")

    with open("rescued_temp.txt", 'w', encoding='utf-8') as f_out:
        for idx, block in enumerate(valid_blocks, 1):
            lines = block.split('\n')
            if len(lines) < 2: continue
            
            old_ip = lines[0].split(',')[0]
            try:
                ip_part, port = old_ip.split(':')
                prefix = ".".join(ip_part.split('.')[:3])
                path = urlparse(lines[1].split(',')[1]).path
                
                print(f"\n[{idx}/{total_blocks}] ğŸ” æ­£åœ¨çˆ†ç ´ C æ®µ: {prefix}.x:{port}")
                print(f"   ç›®æ ‡è·¯å¾„: {path}")
                
                found = False
                tasks_list = [f"http://{prefix}.{i}:{port}{path}" for i in range(1, 255)]
                
                # ç”¨äºè®°å½•æ‰«æè¿›åº¦çš„è®¡æ•°å™¨
                scan_count = 0
                
                with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as exe:
                    future_to_url = {exe.submit(check_url, url): url for url in tasks_list}
                    
                    for fut in concurrent.futures.as_completed(future_to_url):
                        scan_count += 1
                        # æ¯æ‰«æ 50 ä¸ªæ‰“å°ä¸€æ¬¡å°è¿›åº¦ï¼Œé˜²æ­¢çœ‹èµ·æ¥åƒå¡æ­»äº†
                        if scan_count % 50 == 0:
                            print(f"   è¿›åº¦: å·²æ‰«æ {scan_count}/254 ä¸ªåœ°å€...")
                            
                        if fut.result():
                            hit_url = future_to_url[fut]
                            new_host = urlparse(hit_url).netloc
                            print(f"   âœ¨ [æ•‘å›æˆåŠŸ!] åŒ¹é…åœ°å€: {hit_url}")
                            print(f"   ğŸ”„ æ˜ å°„å…³ç³»: {old_ip} -> {new_host}")
                            
                            # å†™å…¥æ–‡ä»¶
                            f_out.write(f"{new_host},#genre#\n")
                            for l in lines[1:]:
                                name, old_url = l.split(',', 1)
                                f_out.write(f"{name},http://{new_host}{urlparse(old_url).path}\n")
                            f_out.write("\n")
                            
                            found = True
                            # å¼ºè¡Œå…³é—­è¯¥ç½‘æ®µçš„å…¶ä»–æ‰«æä»»åŠ¡
                            exe.shutdown(wait=False, cancel_futures=True)
                            break
                
                if not found:
                    print(f"   âŒ [æ‰«æç»“æŸ] è¯¥ç½‘æ®µ 254 ä¸ªåœ°å€å…¨éƒ¨å¤±æ•ˆ")
            
            except Exception as e:
                print(f"   âš ï¸ [è·³è¿‡] å¤„ç†è¯¥ç½‘æ®µæ—¶å‡ºé”™: {e}")

    print("\nğŸ æŠ¢æ•‘é˜¶æ®µå…¨éƒ¨ç»“æŸã€‚")

if __name__ == "__main__":
    main()
