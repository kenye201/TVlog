import re
import requests
from pathlib import Path
import os
import sys
from collections import defaultdict

# ç¦ç”¨ SSL è­¦å‘Šï¼ˆå¿½ç•¥è¿‡æœŸè¯ä¹¦ç­‰ï¼‰
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# -------------------- é…ç½® --------------------
# é“¾æ¥æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ª m3u é“¾æ¥ï¼Œæ”¯æŒ # æ³¨é‡Šï¼‰
LINKS_FILE_PATH = Path("md/httop_links.txt")

# å¯é€‰ï¼šä¿å­˜åŸå§‹ä¸‹è½½çš„ m3u æ–‡ä»¶ï¼ˆæ¨èä¿ç•™ï¼Œä¾¿äºå¤‡ä»½å’Œè°ƒè¯•ï¼‰
SAVE_ORIGINAL_PATH = Path("md/hotel_original.m3u")

ALIAS_FILE = Path("md/alias.txt")
TVLOGO_DIR = Path("Images")
IMG_DIR = Path("img")
OUTPUT_M3U = Path("demo_output.m3u")
OUTPUT_TXT = Path("tvbox_output.txt")
REPO_RAW = "https://raw.githubusercontent.com/kenye201/TVlog/main"

# å†…éƒ¨ä»£å· åˆ° æ˜¾ç¤ºå æ˜ å°„
GROUP_MAPPING = {
    "CCTV": "å¤®è§†é¢‘é“",
    "WSTV": "å«è§†é¢‘é“",
    "CGTN": "å›½é™…é¢‘é“",
    "DOX": "æ±‚ç´¢ç³»åˆ—",
    "NewTV": "æ–°è§†å¬",
    "iHOT": "iHOTç³»åˆ—",
    "img": "åœ°æ–¹é¢‘é“",
    "å…¶ä»–": "å…¶å®ƒé¢‘é“"
}

# åˆ†ç±»æ’åºé¡ºåº
CATEGORY_ORDER = ["4K","å¤®è§†é¢‘é“","å«è§†é¢‘é“","å›½é™…é¢‘é“","CIBN","æ±‚ç´¢ç³»åˆ—","æ–°è§†å¬","iHOTç³»åˆ—",
    "ä¸Šæµ·","äº‘å—","å†…è’™å¤","åŒ—äº¬","å‰æ—","å››å·","å¤©æ´¥","å®å¤",
    "å®‰å¾½","å±±ä¸œ","å±±è¥¿","å¹¿ä¸œ","å¹¿è¥¿","æ•°å­—é¢‘é“","æ–°ç–†","æ±Ÿè‹",
    "æ±Ÿè¥¿","æ²³åŒ—","æ²³å—","æµ™æ±Ÿ","æµ·å—","æµ·å¤–é¢‘é“","æ¸¯æ¾³åœ°åŒº",
    "æ¹–åŒ—","æ¹–å—","ç”˜è‚ƒ","ç¦å»º","è¥¿è—","è´µå·","è¾½å®","é‡åº†",
    "é™•è¥¿","é’æµ·","é»‘é¾™æ±Ÿ","åœ°æ–¹é¢‘é“","å…¶å®ƒé¢‘é“"]

# ==================== 1. ä» md/httop_links.txt ä¸‹è½½ m3u ====================
def download_m3u_from_links() -> str:
    if not LINKS_FILE_PATH.exists():
        print(f"âŒ é“¾æ¥æ–‡ä»¶ä¸å­˜åœ¨: {LINKS_FILE_PATH}")
        sys.exit(1)

    links = []
    for line in LINKS_FILE_PATH.read_text(encoding="utf-8").splitlines():
        line = line.strip()
        if line and not line.startswith("#"):
            links.append(line)

    if not links:
        print(f"âŒ {LINKS_FILE_PATH} ä¸­æ²¡æœ‰æœ‰æ•ˆçš„é“¾æ¥")
        sys.exit(1)

    print(f"ğŸ”— å‘ç° {len(links)} ä¸ªå¾…å°è¯•çš„é“¾æ¥")

    for idx, url in enumerate(links, 1):
        print(f"[{idx}/{len(links)}] æ­£åœ¨å°è¯•ä¸‹è½½: {url}")
        try:
            response = requests.get(url, timeout=30, verify=False)
            response.raise_for_status()
            content = response.text.strip()
            if content.startswith("#EXTM3U") or "#EXTINF" in content:
                print(f"âœ… æˆåŠŸä¸‹è½½æœ‰æ•ˆå†…å®¹: {url}")
                # ä¿å­˜æœ¬æ¬¡æˆåŠŸçš„åŸå§‹å¤‡ä»½
                SAVE_ORIGINAL_PATH.parent.mkdir(parents=True, exist_ok=True)
                save_path = SAVE_ORIGINAL_PATH.with_name(f"hotel_original_success_{idx}.m3u")
                save_path.write_text(content, encoding="utf-8")
                print(f"ğŸ’¾ å·²ä¿å­˜åŸå§‹æ–‡ä»¶: {save_path}")
                # æ›´æ–°ä¸»å¤‡ä»½è·¯å¾„ä¸ºæœ€æ–°æˆåŠŸæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
                content_to_use = content
                SAVE_ORIGINAL_PATH.write_text(content, encoding="utf-8")
                print(f"ğŸ’¾ ä¸»å¤‡ä»½å·²æ›´æ–°: {SAVE_ORIGINAL_PATH}")
                return content_to_use
            else:
                print(f"âš ï¸ ä¸‹è½½å†…å®¹æ— æ•ˆï¼ˆé m3u æ ¼å¼ï¼‰: {url}")
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥ {url}: {e}")

    print("âŒ æ‰€æœ‰é“¾æ¥å‡ä¸‹è½½å¤±è´¥æˆ–å†…å®¹æ— æ•ˆ")
    sys.exit(1)

m3u_content = download_m3u_from_links()

# ==================== 2. åŠ è½½åˆ«åè¡¨ ====================
alias_db = {}
if ALIAS_FILE.exists():
    for line in ALIAS_FILE.read_text(encoding="utf-8").splitlines():
        line = line.strip()
        if not line or line.startswith("#"): 
            continue
        parts = [p.strip() for p in line.split(",") if p.strip()]
        if not parts: 
            continue
        main_name = parts[0]
        alias_db[main_name] = set(parts)

# ==================== 3. åŠ è½½å°æ ‡åº“ ====================
logo_map = {}
def load_logos_from_dir(directory: Path, base_cat: str = None) -> int:
    if not directory.exists(): 
        return 0
    new_aliases = 0
    for f in directory.iterdir():
        if not f.is_file() or f.suffix.lower() not in {".png",".jpg",".jpeg",".webp"}: 
            continue
       
        cat = base_cat if base_cat is not None else directory.name
        logo_stem = f.stem
        logo_name = f.name
       
        # é˜¶æ®µ A: é€šè¿‡ alias.txt æ˜ å°„
        main_name_found = None
        for main, aliases in alias_db.items():
            clean_logo_stem = re.sub(r"[-_ .]","", logo_stem).upper()
            for alias in aliases:
                clean_alias = re.sub(r"[-_ .]","", alias).upper()
                if clean_logo_stem == clean_alias:
                    main_name_found = main
                    break
            if main_name_found: 
                break
       
        if main_name_found:
            all_aliases = alias_db.get(main_name_found, {main_name_found})
            for alias in all_aliases:
                keys_to_add = {
                    alias.upper(),
                    re.sub(r"[-_ .]","", alias).upper(),
                    re.sub(r"(é«˜æ¸…|HD|è¶…æ¸…|4K|PLUS).*$","", alias, flags=re.I).strip().upper()
                }
                for k in keys_to_add:
                    if k and k not in logo_map:
                        logo_map[k] = (cat, logo_name)
                        new_aliases += 1
       
        # é˜¶æ®µ B: æ·»åŠ æ–‡ä»¶åæœ¬èº«æ˜ å°„
        clean_stem = re.sub(r"[-_ .]","", logo_stem).upper()
        if logo_stem.upper() not in logo_map:
            logo_map[logo_stem.upper()] = (cat, logo_name)
            new_aliases += 1
        if clean_stem not in logo_map:
            logo_map[clean_stem] = (cat, logo_name)
            new_aliases += 1
   
    return new_aliases

total_aliases = 0
if TVLOGO_DIR.exists():
    for folder in TVLOGO_DIR.iterdir():
        if folder.is_dir():
            total_aliases += load_logos_from_dir(folder)
if IMG_DIR.exists():
    total_aliases += load_logos_from_dir(IMG_DIR, base_cat='img')
print(f"å°æ ‡åº“åŠ è½½å®Œæˆï¼šå…±æ˜ å°„ {total_aliases} ä¸ªé¢‘é“åç§°å˜ä½“ã€‚")

# ==================== 4. ä¸»ç¨‹åºï¼ˆè§£æä¸‹è½½çš„ m3u å†…å®¹ï¼‰ ====================
grouped_channels = defaultdict(lambda: defaultdict(list))
total = 0
extinf = None
for raw in m3u_content.splitlines():
    line = raw.strip()
   
    if line.startswith("#EXTINF:"):
        extinf = line
    elif line and not line.startswith("#"):
        if not extinf:
            extinf = None
            continue
       
        raw_name = extinf.split(",",1)[-1].strip() if "," in extinf else ""
        name_upper = raw_name.upper()
        stream_url = line
        skip_processing = False
       
        # A. é¢„å¤„ç†ï¼šçº¯æ•°å­—é¢‘é“ä¿ç•™
        if not raw_name or raw_name.isdigit():
            final_group_internal = "å…¶ä»–"
            new_line = extinf
            skip_processing = True
       
        if not skip_processing:
            # B. æŸ¥æ‰¾å°æ ‡
            logo_url = ""
            best_match_cat = None
           
            aggressive_clean_name = raw_name
            for suffix in ["é¢‘é“", "å«è§†", "å°", "é«˜æ¸…", "HD", "è¶…æ¸…", "4K", "PLUS"]:
                aggressive_clean_name = re.sub(f'{re.escape(suffix)}$', '', aggressive_clean_name, flags=re.I).strip()
           
            candidates = {
                name_upper,
                re.sub(r"[-_ .]","", name_upper),
                aggressive_clean_name.upper(),
                re.sub(r"[-_ .]","", aggressive_clean_name).upper()
            }
           
            for key in candidates:
                if logo_map.get(key):
                    best_match_cat, logo_file = logo_map[key]
                    if best_match_cat == 'img':
                        logo_url = f"{REPO_RAW}/img/{logo_file}"
                    else:
                        logo_url = f"{REPO_RAW}/Images/{best_match_cat}/{logo_file}"
                    break
           
            # C. ç¡®å®šæœ€ç»ˆ Group
            final_group_internal = "å…¶ä»–"
            if any(x in name_upper for x in ["CCTV","å¤®è§†","ä¸­å¤®","CGTN"]):
                final_group_internal = "CCTV"
            elif "å«è§†" in name_upper:
                final_group_internal = "WSTV"
            elif logo_url and best_match_cat and best_match_cat != 'å…¶ä»–':
                final_group_internal = best_match_cat
            else:
                m = re.search(r'group-title="([^"]+)"', extinf)
                final_group_internal = m.group(1) if m else "å…¶ä»–"
           
            # D. æ„é€ æ–°çš„ EXTINF
            group_display_name = GROUP_MAPPING.get(final_group_internal, final_group_internal)
            new_line = extinf.split(",",1)[0]
            new_line = re.sub(r'group-title="[^"]*"', f'group-title="{group_display_name}"', new_line)
            if "group-title=" not in new_line:
                new_line += f' group-title="{group_display_name}"'
            if logo_url:
                new_line = re.sub(r'tvg-logo="[^"]*"', f'tvg-logo="{logo_url}"', new_line)
                if "tvg-logo=" not in new_line:
                    new_line += f' tvg-logo="{logo_url}"'
            new_line += f',{raw_name}'
       
        # E. ä¿å­˜ç»“æœ
        group_display_name = GROUP_MAPPING.get(final_group_internal, final_group_internal)
        weight = CATEGORY_ORDER.index(group_display_name) if group_display_name in CATEGORY_ORDER else 9999
       
        cctv_match = re.search(r'CCTV[^\d]*(\d+)', raw_name, re.I)
        if cctv_match:
            channel_number = int(cctv_match.group(1))
            channel_sort_key = (0, channel_number)
        else:
            channel_sort_key = (1, raw_name)
       
        grouped_channels[final_group_internal][raw_name].append({
            'weight': weight,
            'channel_sort_key': channel_sort_key,
            'extinf': new_line,
            'url': stream_url
        })
        total += 1
        extinf = None

# ==================== 5. æ’åº + å†™å…¥æ–‡ä»¶ ====================
def get_sort_key(group_internal_name):
    display_name = GROUP_MAPPING.get(group_internal_name, group_internal_name)
    return CATEGORY_ORDER.index(display_name) if display_name in CATEGORY_ORDER else 9999

sorted_groups_internal = sorted(grouped_channels.keys(), key=get_sort_key)
m3u_lines = ['#EXTM3U x-tvg-url="https://live.fanmingming.com/e.xml"']
txt_lines = []

for group_internal_name in sorted_groups_internal:
    channels = grouped_channels[group_internal_name]
    group_display_name = GROUP_MAPPING.get(group_internal_name, group_internal_name)
   
    sorted_channels = sorted(channels.keys(), key=lambda c: channels[c][0]['channel_sort_key'])
   
    txt_lines.append(f"{group_display_name},#genre#")
    txt_lines.append("")  # ç©ºè¡Œåˆ†éš”
   
    for channel_name in sorted_channels:
        links = channels[channel_name]
        for item in links:
            m3u_lines.append(item['extinf'])
            m3u_lines.append(item['url'])
            txt_lines.append(f"{channel_name},{item['url']}")

# å†™å…¥ M3U
try:
    OUTPUT_M3U.write_text('\n'.join(m3u_lines) + '\n', encoding="utf-8")
    print(f"âœ… å·²ç”Ÿæˆ M3U æ–‡ä»¶: {OUTPUT_M3U.name}")
except Exception as e:
    print(f"âŒ å†™å…¥ M3U å¤±è´¥: {e}")

# å†™å…¥ TXT
try:
    OUTPUT_TXT.write_text('\n'.join(txt_lines) + '\n', encoding="utf-8")
    print(f"âœ… å·²ç”Ÿæˆ TVbox TXT æ–‡ä»¶: {OUTPUT_TXT.name}")
except Exception as e:
    print(f"âŒ å†™å…¥ TXT å¤±è´¥: {e}")

print(f"ğŸ‰ å®Œç¾æ”¶å·¥ï¼å…±å¤„ç† {total} æ¡çº¿è·¯ï¼ˆåŒ…å«çº¯æ•°å­—é¢‘é“ï¼‰")
