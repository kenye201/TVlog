import os, requests, concurrent.futures, re
from urllib.parse import urlparse

# --- é…ç½®åŒº ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PARENT_DIR = os.path.dirname(CURRENT_DIR)
MERGED_SOURCE = os.path.join(PARENT_DIR, "history", "merged.txt")
MANUAL_FIX = os.path.join(CURRENT_DIR, "manual_fix.txt")

TIMEOUT = 2
MAX_WORKERS_CHECK = 100 
MAX_WORKERS_RESCUE = 5   # åŒæ—¶æ‰«æçš„ C æ®µä»»åŠ¡æ•°
MAX_THREADS_PER_C = 25  # æ¯ä¸ª C æ®µå†…éƒ¨çš„æ¢æµ‹å¹¶å‘æ•°

# ä½¿ç”¨ Session æå‡è¿æ¥æ•ˆç‡
session = requests.Session()
adapter = requests.adapters.HTTPAdapter(pool_connections=100, pool_maxsize=100)
session.mount('http://', adapter)
session.mount('https://', adapter)

def check_url(url):
    try:
        # stream=True é…åˆ close()ï¼Œåªè¯»å¤´éƒ¨ä¸è¯»æ­£æ–‡ï¼Œé€Ÿåº¦æœ€å¿«
        with session.get(url, timeout=TIMEOUT, stream=True, headers={"User-Agent":"VLC/3.0"}) as r:
            return r.status_code == 200
    except:
        return False

found_alive_ips = set()

def rescue_task(base_ip_port, channels):
    """åœ°æ¯¯å¼æ‰«ææ•´ä¸ª C æ®µ"""
    ip_parts = base_ip_port.split(':')
    if len(ip_parts) != 2: return []
    ip, port = ip_parts
    if not re.match(r'^\d+\.\d+\.\d+\.\d+$', ip): return []
        
    prefix = '.'.join(ip.split('.')[:-1])
    path = channels[0].split(',')[1].split(base_ip_port)[-1]
    
    print(f"ğŸ” æŒ–æ˜ä¸­: {prefix}.0/24:{port}")
    
    discovered_blocks = []
    test_tasks = [(f"{prefix}.{i}:{port}", f"http://{prefix}.{i}:{port}{path}") for i in range(1, 256)]

    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_THREADS_PER_C) as inner_executor:
        future_to_ip = {inner_executor.submit(check_url, url): t_ip for t_ip, url in test_tasks}
        for future in concurrent.futures.as_completed(future_to_ip):
            target_ip = future_to_ip[future]
            if future.result():
                if target_ip not in found_alive_ips:
                    found_alive_ips.add(target_ip)
                    print(f"  âœ¨ [å‘½ä¸­] {target_ip}")
                    block = f"{target_ip},#genre#\n"
                    for ch in channels:
                        name, old_url = ch.split(',', 1)
                        new_url = old_url.replace(base_ip_port, target_ip)
                        block += f"{name},{new_url}\n"
                    discovered_blocks.append(block + "\n")
    return discovered_blocks

def main():
    # å¯åŠ¨å‰æ‹‰å–æœ€æ–°ä»£ç ï¼Œé˜²æ­¢åº•åº“è¿‡æ—§
    os.system("git pull --rebase origin main")
    
    if not os.path.exists(MERGED_SOURCE): return

    ip_groups = {}
    with open(MERGED_SOURCE, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            line = line.strip()
            if "," not in line or "http" not in line: continue
            url = line.split(',', 1)[1].strip()
            ip_port = urlparse(url).netloc
            if ip_port:
                if ip_port not in ip_groups: ip_groups[ip_port] = []
                ip_groups[ip_port].append(line)

    final_results = []
    to_rescue = []

    print(f"ğŸ“¡ é˜¶æ®µ 1ï¼šå¿«é€Ÿç­›é€‰ç›´è¿å­˜æ´»...")
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS_CHECK) as executor:
        future_to_ip = {executor.submit(check_url, data[0].split(',')[1]): ip for ip, data in ip_groups.items()}
        for future in concurrent.futures.as_completed(future_to_ip):
            ip_port = future_to_ip[future]
            if future.result():
                if ip_port not in found_alive_ips:
                    found_alive_ips.add(ip_port)
                    final_results.append(f"{ip_port},#genre#\n" + "\n".join(ip_groups[ip_port]) + "\n\n")
            else:
                to_rescue.append(ip_port)

    if to_rescue:
        print(f"ğŸš€ é˜¶æ®µ 2ï¼šæ·±åº¦æŒ–æ˜ {len(to_rescue)} ä¸ªå¤±æ•ˆç½‘æ®µ...")
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS_RESCUE) as executor:
            rescue_futures = {executor.submit(rescue_task, ip, ip_groups[ip]): ip for ip in to_rescue}
            for future in concurrent.futures.as_completed(rescue_futures):
                blocks = future.result()
                if blocks: final_results.extend(blocks)

    if final_results:
        with open(MANUAL_FIX, 'w', encoding='utf-8') as f:
            f.writelines(final_results)
        print(f"ğŸ‰ æŒ–æ˜ç»“æŸï¼Œå…±ä¿å­˜ {len(found_alive_ips)} ä¸ªå­˜æ´»æºã€‚")

if __name__ == "__main__":
    main()
