import os, requests, concurrent.futures, re
from urllib.parse import urlparse

# --- é…ç½®åŒº ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PARENT_DIR = os.path.dirname(CURRENT_DIR)
MERGED_SOURCE = os.path.join(PARENT_DIR, "history", "merged.txt")
MANUAL_FIX = os.path.join(CURRENT_DIR, "manual_fix.txt")

TIMEOUT = 3
MAX_WORKERS_CHECK = 100 # ç¬¬ä¸€æ­¥å¿«æµ‹ï¼šå¹¶å‘å¼€å¤§
MAX_WORKERS_RESCUE = 100 # ç¬¬äºŒæ­¥çˆ†ç ´ï¼šæ€»å¹¶å‘æ§åˆ¶

def extract_ip_port(url):
    try:
        parsed = urlparse(url)
        if parsed.netloc: return parsed.netloc
    except: return None
    return None

def check_url(url):
    """æ£€æµ‹å•ä¸ª URL æ˜¯å¦å­˜æ´»"""
    try:
        r = requests.get(url, timeout=TIMEOUT, stream=True, headers={"User-Agent":"VLC/3.0"})
        return r.status_code == 200
    except:
        return False

def rescue_task(base_ip_port, channels):
    """Cæ®µçˆ†ç ´å•ä¸ªç½‘æ®µçš„ä»»åŠ¡å‡½æ•°"""
    ip, port = base_ip_port.split(':')
    # è¿‡æ»¤æ‰é IP çš„åŸŸåï¼ˆåŸŸåæ— æ³•çˆ†ç ´ C æ®µï¼‰
    if not re.match(r'^\d+\.\d+\.\d+\.\d+$', ip):
        return None
        
    prefix = '.'.join(ip.split('.')[:-1])
    path = channels[0].split(',')[1].split(base_ip_port)[-1]
    
    # æ„é€ è¯¥ C æ®µæ‰€æœ‰ 255 ä¸ªæ¢æµ‹åœ°å€
    for i in range(1, 256):
        target_ip = f"{prefix}.{i}:{port}"
        if target_ip == base_ip_port: continue # è·³è¿‡å·²çŸ¥çš„æ­» IP
        
        test_url = f"http://{target_ip}{path}"
        if check_url(test_url):
            # åªè¦æ‰¾åˆ°ä¸€ä¸ªæ´»çš„ï¼Œç«‹å³è¿”å›å—å†…å®¹
            block = f"{target_ip},#genre#\n"
            for ch in channels:
                name, old_url = ch.split(',', 1)
                new_url = old_url.replace(base_ip_port, target_ip)
                block += f"{name},{new_url}\n"
            return block + "\n"
    return None

def main():
    if not os.path.exists(MERGED_SOURCE):
        print("âŒ æœªæ‰¾åˆ° history/merged.txt")
        return

    # 1. è§£æå½’ç±»
    ip_groups = {}
    with open(MERGED_SOURCE, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            line = line.strip()
            if "," not in line or "http" not in line: continue
            parts = line.split(',', 1)
            ip_port = extract_ip_port(parts[1].strip())
            if ip_port:
                if ip_port not in ip_groups: ip_groups[ip_port] = []
                ip_groups[ip_port].append(line)

    print(f"ğŸ“– åŸºå› åº“è§£æå®Œæˆï¼Œå…± {len(ip_groups)} ä¸ªåŸå§‹ç½‘æ®µã€‚")
    
    final_results = []
    to_rescue = [] # å­˜æ”¾å¤±æ•ˆç½‘æ®µè¿›è¡Œçˆ†ç ´

    # --- ç¬¬ä¸€æ­¥ï¼šå¹¶å‘å¿«æµ‹åŸå§‹ IP ---
    print(f"ğŸ“¡ é˜¶æ®µ 1ï¼šæ­£åœ¨å¿«é€Ÿæ£€æµ‹åŸå§‹ IP å­˜æ´»æƒ…å†µ...")
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS_CHECK) as executor:
        future_to_ip = {executor.submit(check_url, data[0].split(',')[1]): ip for ip, data in ip_groups.items()}
        for future in concurrent.futures.as_completed(future_to_ip):
            ip_port = future_to_ip[future]
            if future.result():
                print(f"âœ… [ç›´è¿å­˜æ´»] {ip_port}")
                block = f"{ip_port},#genre#\n" + "\n".join(ip_groups[ip_port]) + "\n\n"
                final_results.append(block)
            else:
                to_rescue.append(ip_port)

    print(f"ğŸ“Š ç»Ÿè®¡ï¼šç›´è¿æˆåŠŸ {len(final_results)} ä¸ªï¼Œå¾…çˆ†ç ´æŠ¢æ•‘ {len(to_rescue)} ä¸ªã€‚")

    # --- ç¬¬äºŒæ­¥ï¼šå¹¶å‘æ‰§è¡Œ C æ®µçˆ†ç ´ ---
    if to_rescue:
        print(f"ğŸš€ é˜¶æ®µ 2ï¼šå¼€å§‹å¹¶è¡Œ C æ®µçˆ†ç ´ï¼ˆè€—æ—¶è¾ƒé•¿ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰...")
        # é™åˆ¶çˆ†ç ´ä»»åŠ¡çš„å¹¶å‘ï¼Œé˜²æ­¢ CPU/å¸¦å®½ ç¬é—´è¿‡è½½
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            rescue_futures = {executor.submit(rescue_task, ip, ip_groups[ip]): ip for ip in to_rescue}
            for future in concurrent.futures.as_completed(rescue_futures):
                orig_ip = rescue_futures[future]
                result_block = future.result()
                if result_block:
                    print(f"âœ¨ [æŠ¢æ•‘æˆåŠŸ] åŸå§‹: {orig_ip}")
                    final_results.append(result_block)
                else:
                    # print(f"ğŸ’€ [å½»åº•å¤±æ•ˆ] {orig_ip}")
                    pass

    # 3. å†™å…¥æ–‡ä»¶
    if final_results:
        with open(MANUAL_FIX, 'w', encoding='utf-8') as f:
            f.writelines(final_results)
        print(f"ğŸ‰ ä»»åŠ¡å®Œæˆï¼å…±å¯¼å‡º {len(final_results)} ä¸ªæ´»ç½‘æ®µè‡³ manual_fix.txt")

if __name__ == "__main__":
    main()
