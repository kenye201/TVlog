import os, requests, concurrent.futures, re

# --- è·¯å¾„é…ç½® ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PARENT_DIR = os.path.dirname(CURRENT_DIR)
MERGED_SOURCE = os.path.join(PARENT_DIR, "history", "merged.txt")
MANUAL_FIX = os.path.join(CURRENT_DIR, "manual_fix.txt")

TIMEOUT = 3
MAX_WORKERS = 30

def is_valid_ip(ip_str):
    pattern = r'^(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(\.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+):[0-9]+$'
    return bool(re.match(pattern, ip_str))

def load_existing_ips(path):
    """è·å– manual_fix.txt ä¸­å·²ç»å­˜åœ¨çš„ IPï¼Œé¿å…é‡å¤æ·»åŠ """
    ips = set()
    if not os.path.exists(path): return ips
    with open(path, 'r', encoding='utf-8') as f:
        for line in f:
            if "#genre#" in line:
                ips.add(line.split(',')[0].strip())
    return ips

def main():
    existing_ips = load_existing_ips(MANUAL_FIX)
    new_ip_map = {} # å­˜æ”¾æ–°å‘ç°çš„ IP ä¿¡æ¯

    # 1. åŠ è½½å¤§åº“ä¸­ manual_fix é‡Œæ²¡æœ‰çš„ IP
    print(f"ğŸ“– æ­£åœ¨æ‰«æå…¨é‡å¤§åº“: {MERGED_SOURCE}")
    with open(MERGED_SOURCE, 'r', encoding='utf-8', errors='ignore') as f:
        cur_ip = None
        for line in f:
            line = line.strip()
            if not line: continue
            if "#genre#" in line:
                ip = line.split(',')[0].strip()
                # åªæ¢æµ‹ manual_fix é‡Œæ²¡æœ‰çš„
                if is_valid_ip(ip) and ip not in existing_ips:
                    cur_ip = ip
                    new_ip_map[cur_ip] = []
                else:
                    cur_ip = None
                continue
            if ',' in line and cur_ip:
                new_ip_map[cur_ip].append(line)

    if not new_ip_map:
        print("âœ… å¤§åº“ä¸­çš„æ‰€æœ‰ IP å·²åœ¨æ‰‹åŠ¨è¡¥ä¸æ–‡ä»¶ä¸­ï¼Œæ— éœ€æ‰«æã€‚")
        return

    print(f"ğŸ“¡ å‘ç° {len(new_ip_map)} ä¸ªæ–°åŸºå› ï¼Œå¼€å§‹æé€ŸéªŒè¯...")

    # 2. æ¢æµ‹é€»è¾‘
    discovered_blocks = []
    
    def check(ip):
        try:
            # æŠ½æ ·æ£€æµ‹è¯¥ IP çš„ç¬¬ä¸€ä¸ªé¢‘é“
            test_url = new_ip_map[ip][0].split(',')[1].strip()
            r = requests.get(test_url, timeout=TIMEOUT, stream=True)
            return ip, r.status_code == 200
        except: return ip, False

    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as exe:
        futures = {exe.submit(check, ip): ip for ip in new_ip_map}
        for f in concurrent.futures.as_completed(futures):
            ip, ok = f.result()
            if ok:
                print(f"ğŸŒŸ [æ–°å‘ç°] {ip}")
                block = f"{ip},#genre#\n" + "\n".join(new_ip_map[ip]) + "\n\n"
                discovered_blocks.append(block)

    # 3. è¿½åŠ æ¨¡å¼å†™å…¥ manual_fix.txt
    if discovered_blocks:
        with open(MANUAL_FIX, 'a', encoding='utf-8') as f:
            f.writelines(discovered_blocks)
        print(f"âœ… æˆåŠŸå°† {len(discovered_blocks)} ä¸ªæ–° IP è¿½åŠ åˆ° {MANUAL_FIX}")
    else:
        print("æŸ¥æ— æ–°æ´» IPã€‚")

if __name__ == "__main__":
    main()
