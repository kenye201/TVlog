import os, requests, concurrent.futures, re

# --- è·¯å¾„é…ç½® ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PARENT_DIR = os.path.dirname(CURRENT_DIR)
MERGED_SOURCE = os.path.join(PARENT_DIR, "history", "merged.txt")
MANUAL_FIX = os.path.join(CURRENT_DIR, "manual_fix.txt")

TIMEOUT = 3
MAX_WORKERS = 50 # æŒ–çŸ¿è„šæœ¬ï¼Œçº¿ç¨‹å¼€å¤§ä¸€ç‚¹

def is_valid_ip(ip_str):
    """åŒæ—¶åŒ¹é… IP:Port å’Œ åŸŸå:Port"""
    pattern = r'^(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(\.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+):[0-9]+$'
    return bool(re.match(pattern, ip_str))

def load_existing_ips(path):
    """è¯»å–å·²æœ‰çš„è¡¥ä¸åº“ IPï¼Œé¿å…é‡å¤è¿½åŠ """
    ips = set()
    if not os.path.exists(path): return ips
    with open(path, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            if "#genre#" in line:
                parts = line.split(',')
                if parts: ips.add(parts[0].strip())
    return ips

def main():
    existing_ips = load_existing_ips(MANUAL_FIX)
    all_ip_data = {} # { "IP:Port": [é¢‘é“åˆ—è¡¨] }

    print(f"ğŸ“– æ­£åœ¨æ‰«ææ±‡æ€»æº: {MERGED_SOURCE}")
    if not os.path.exists(MERGED_SOURCE):
        print("âŒ é”™è¯¯ï¼šæºæ–‡ä»¶ä¸å­˜åœ¨")
        return

    # --- 1. æ”¹è¿›çš„è§£æå™¨ ---
    with open(MERGED_SOURCE, 'r', encoding='utf-8', errors='ignore') as f:
        current_ip = None
        for line in f:
            line = line.strip()
            if not line: continue
            
            # è¯†åˆ« IP åˆ†ç»„è¡Œ (ä¾‹å¦‚: 122.114.131.154:8080,#genre#)
            if "#genre#" in line:
                ip_part = line.split(',')[0].strip()
                if is_valid_ip(ip_part):
                    current_ip = ip_part
                    if current_ip not in all_ip_data:
                        all_ip_data[current_ip] = []
                continue
            
            # è¯†åˆ«é¢‘é“è¡Œ (ä¾‹å¦‚: CCTV1,http://...)
            if "," in line and current_ip:
                all_ip_data[current_ip].append(line)

    # è¿‡æ»¤æ‰ manual_fix é‡Œå·²ç»å­˜åœ¨çš„ IP
    targets = {ip: data for ip, data in all_ip_data.items() if ip not in existing_ips}
    
    print(f"ğŸ“¡ åŸºå› åº“æ€»è®¡: {len(all_ip_data)} ä¸ª IP")
    print(f"ğŸ” è¡¥ä¸åº“å·²å­˜: {len(existing_ips)} ä¸ª IP")
    print(f"ğŸš€ æœ¬æ¬¡å¾…æµ‹æ–° IP: {len(targets)} ä¸ª")

    if not targets:
        print("âœ¨ æ²¡æœ‰å‘ç°æ–° IPã€‚")
        return

    # --- 2. æ¢æµ‹å­˜æ´» ---
    newly_discovered = []
    
    def check_worker(ip):
        try:
            # æŠ½æ ·æ£€æµ‹è¯¥ IP ä¸‹ç¬¬ä¸€ä¸ªé¢‘é“
            test_url = targets[ip][0].split(',')[1].strip()
            # æ¨¡æ‹Ÿ VLC è¯·æ±‚
            r = requests.get(test_url, timeout=TIMEOUT, stream=True, headers={"User-Agent": "VLC/3.0"})
            if r.status_code == 200:
                return ip, True
        except:
            pass
        return ip, False

    

    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_ip = {executor.submit(check_worker, ip): ip for ip in targets}
        for future in concurrent.futures.as_completed(future_to_ip):
            ip, is_alive = future.result()
            if is_alive:
                print(f"ğŸŒŸ [å‘ç°æ–°å­˜æ´»] {ip}")
                # æ„é€ æ ‡å‡†å—
                block = f"{ip},#genre#\n" + "\n".join(targets[ip]) + "\n\n"
                newly_discovered.append(block)

    # --- 3. è¿½åŠ å†™å…¥ ---
    if newly_discovered:
        # ä½¿ç”¨ 'a' è¿½åŠ æ¨¡å¼ï¼Œä¸ç ´åä½ æ‰‹åŠ¨æ”¹å¥½çš„ manual_fix.txt å‰é¢éƒ¨åˆ†
        with open(MANUAL_FIX, 'a', encoding='utf-8') as f:
            f.writelines(newly_discovered)
        print(f"âœ… æˆåŠŸè¿½åŠ  {len(newly_discovered)} ä¸ªæ–°ç½‘æ®µåˆ° manual_fix.txt")
    else:
        print("æœ¬æ¬¡æœªå‘ç°æ–°å­˜æ´»ç½‘æ®µã€‚")

if __name__ == "__main__":
    main()
