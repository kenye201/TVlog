import subprocess
import json
import os
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- é…ç½®åŒº ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
INPUT_FILE = os.path.join(CURRENT_DIR, "aggregated_hotel.txt")
OUTPUT_FILE = os.path.join(CURRENT_DIR, "test_result.txt")

# CCTV æ ‡å‡†æ˜ å°„
CCTV_MAP = {
    'CCTV1': 'CCTV-1', 'CCTV2': 'CCTV-2', 'CCTV3': 'CCTV-3', 'CCTV4': 'CCTV-4',
    'CCTV5': 'CCTV-5', 'CCTV5+': 'CCTV-5+', 'CCTV6': 'CCTV-6', 'CCTV7': 'CCTV-7',
    'CCTV8': 'CCTV-8', 'CCTV9': 'CCTV-9', 'CCTV10': 'CCTV-10', 'CCTV11': 'CCTV-11',
    'CCTV12': 'CCTV-12', 'CCTV13': 'CCTV-13', 'CCTV14': 'CCTV-14', 'CCTV15': 'CCTV-15',
    'CCTV16': 'CCTV-16', 'CCTV17': 'CCTV-17'
}

def get_stream_quality(url):
    """
    æ·±åº¦æ¢æµ‹å‡½æ•°ï¼šåŒ…å«3æ¬¡é‡è¯•ï¼Œå¢åŠ é‡‡æ ·æ·±åº¦
    """
    for attempt in range(3):
        # å¢åŠ  analyzeduration å’Œ probesize ä»¥ç¡®ä¿è¯»å–åˆ°è§†é¢‘å¤´ä¿¡æ¯
        # timeout å•ä½ä¸ºå¾®ç§’ï¼Œ15000000 = 15ç§’
        cmd = [
            'ffprobe', '-v', 'quiet', '-select_streams', 'v:0',
            '-show_entries', 'stream=width,height', '-of', 'json',
            '-analyzeduration', '15000000', 
            '-probesize', '15000000',       
            '-timeout', '15000000',         
            url
        ]
        try:
            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            data = json.loads(result.stdout)
            if 'streams' in data and len(data['streams']) > 0:
                w = data['streams'][0].get('width', 0)
                h = data['streams'][0].get('height', 0)
                if h >= 1080 or w >= 1920: return "1080P"
                if h >= 720 or w >= 1280: return "720P"
                return "SD"
        except Exception:
            pass
        
        # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç¨ä½œç­‰å¾…å†é‡è¯•
        if attempt < 2:
            time.sleep(2) 
            
    return "Unknown"

def clean_and_sort_key(name):
    """å½»åº•æ¸…æ´—åç§°å¹¶è¿”å›æ ‡å‡†åå’Œæ’åºæƒé‡"""
    # å»é™¤æ‰€æœ‰æ‹¬å·åŠå…¶å†…å®¹ï¼Œå¦‚ (SD), (Unknown)
    clean = re.sub(r'\(.*?\)', '', name)
    # è½¬å¤§å†™å¹¶å»é™¤å¸¸è§æ‚è´¨
    clean = clean.upper().replace(' ', '').replace('-', '').replace('ä¸­å¤®', '').replace('å°', '').replace('PLUS', '+')
    
    for key, std_name in CCTV_MAP.items():
        if key in clean:
            num_match = re.search(r'\d+', std_name)
            order = int(num_match.group()) if num_match else 0
            if '5+' in std_name: order = 5.5
            return std_name, order
            
    return name.strip(), 999

def process_ip_group(index, total, block):
    """å¤„ç†å•ä¸ª IP åˆ†ç»„"""
    lines = [l.strip() for l in block.strip().split('\n') if l.strip()]
    if not lines: return None
    
    # è·å– IP æ ‡é¢˜å’Œæµ‹è¯•é“¾æ¥
    raw_ip = lines[0].split(',')[0]
    test_url = lines[1].split(',')[1] if len(lines) > 1 else ""
    
    # æ‰§è¡Œæ·±åº¦æ¢æµ‹
    quality = get_stream_quality(test_url)
    
    # å®æ—¶åé¦ˆæ—¥å¿—
    icon = "âœ…" if quality == "1080P" else ("âš ï¸" if quality == "Unknown" else "â„¹ï¸")
    print(f"[{index}/{total}] {icon} æ¢æµ‹: {raw_ip} -> {quality}", flush=True)
    
    # æ ¹æ®è¦æ±‚æ„å»ºåˆ†ç±»æ ‡é¢˜
    if quality in ["SD", "720P"]:
        new_header = f"{raw_ip}(SD),#genre#"
    elif quality == "Unknown":
        new_header = f"{raw_ip}(Unknown),#genre#"
    else:
        new_header = f"{raw_ip},#genre#"
        
    processed_channels = []
    for l in lines[1:]:
        if ',' in l:
            name, url = l.split(',', 1)
            std_name, sort_order = clean_and_sort_key(name)
            # å­˜å…¥åˆ—è¡¨ç”¨äºæ’åº
            processed_channels.append({
                'order': sort_order,
                'line': f"{std_name},{url.strip()}"
            })
    
    # ç»„å†…æ‰§è¡Œæ’åºï¼ˆå¤®è§† 1-17 ä¼˜å…ˆï¼‰
    processed_channels.sort(key=lambda x: x['order'])
    
    result = [new_header] + [ch['line'] for ch in processed_channels]
    return "\n".join(result)

def main():
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {INPUT_FILE}")
        return

    print(f"--- ğŸš€ é…’åº—æºæ·±åº¦æ´—ç‰ˆæ¢æµ‹å¼€å§‹ ---", flush=True)
    
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        content = f.read().strip()
    
    # ä»¥åŒæ¢è¡Œç¬¦åˆ†å‰²ç½‘æ®µ
    groups = [g.strip() for g in content.split('\n\n') if g.strip()]
    total = len(groups)
    
    # å­˜å‚¨ç»“æœå­—å…¸ä»¥ä¿æŒåŸå§‹ IP å—é¡ºåº
    indexed_results = {}
    
    # é™ä½å¹¶å‘è‡³ 5ï¼Œç¡®ä¿æ¯ä¸ªè¿æ¥æœ‰è¶³å¤Ÿçš„å¸¦å®½å’Œç¨³å®šæ€§
    with ThreadPoolExecutor(max_workers=5) as executor:
        future_to_index = {executor.submit(process_ip_group, i+1, total, groups[i]): i for i in range(total)}
        for future in as_completed(future_to_index):
            idx = future_to_index[future]
            indexed_results[idx] = future.result()

    # æŒ‰ç…§ index é¡ºåºåˆå¹¶
    final_list = [indexed_results[i] for i in range(total) if indexed_results[i]]
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write("\n\n".join(final_list))
    
    print(f"\nâœ¨ ä»»åŠ¡åœ†æ»¡å®Œæˆï¼", flush=True)
    print(f"ğŸ“‚ ç»“æœæ–‡ä»¶: {OUTPUT_FILE}", flush=True)

if __name__ == "__main__":
    main()
