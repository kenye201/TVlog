import os, sys, requests, re, concurrent.futures
from urllib.parse import urlparse

# é…ç½®
INPUT_RAW = "tvbox_output.txt"
LOCAL_BASE = "md/aggregated_hotel.txt"
MID_REVIVED = "revived_temp.txt"
MID_DEAD = "dead_tasks.txt"
TIMEOUT = 3
MAX_WORKERS = 30

def is_valid_ip(ip_str):
    """æ ¡éªŒ IP:Port æˆ– åŸŸå:Port"""
    pattern = r'^(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(\.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+):[0-9]+$'
    return bool(re.match(pattern, ip_str))

def main():
    ip_map = {} # å­—å…¸åµŒå¥—ç»“æ„ï¼Œè‡ªåŠ¨å»é‡

    def load_data(path, label):
        if not os.path.exists(path): return
        print(f"ğŸ“– æ­£åœ¨åŠ è½½ {label}: {path}", flush=True)
        with open(path, 'r', encoding='utf-8', errors='ignore') as f:
            cur_ip = None
            for line in f:
                line = line.strip()
                if not line: continue
                if "#genre#" in line:
                    potential_ip = line.split(',')[0].strip()
                    if is_valid_ip(potential_ip):
                        cur_ip = potential_ip
                        if cur_ip not in ip_map: ip_map[cur_ip] = {}
                    else: cur_ip = None
                    continue
                if ',' in line and cur_ip:
                    name, url = line.split(',', 1)
                    # å…³é”®ä¿®æ”¹ï¼šå¦‚æœåº•åº“å·²ç»æœ‰çš„é¢‘é“ï¼Œç»å¯¹ä¸è¦†ç›–ï¼Œä¿æŠ¤æ‰‹åŠ¨ä¿®æ”¹
                    if name.strip() not in ip_map[cur_ip]:
                        ip_map[cur_ip][name.strip()] = url.strip()

    # ï¼ï¼ï¼é¡ºåºè‡³å…³é‡è¦ï¼šå…ˆåŠ è½½åº•åº“ï¼ˆä½ çš„ä¿®æ”¹ï¼‰ï¼Œå†åŠ è½½æŠ“å–æºï¼ï¼ï¼
    load_data("aggregated_hotel.txt", "æ‰‹åŠ¨åº•åº“")
    load_data("tvbox_output.txt", "æ–°æŠ“å–æº")

    all_ips = list(ip_map.keys())
    total_ips = len(all_ips)
    print(f"ğŸ“¡ å…±æœ‰ {total_ips} ä¸ªæœ‰æ•ˆ IP ç½‘æ®µå‚ä¸æ¢æµ‹...", flush=True)

    revived, dead = [], []
    processed = 0

    def check(ip):
        try:
            # å–è¯¥ IP ä¸‹çš„ç¬¬ä¸€ä¸ªé¢‘é“æµ‹è¯•
            first_name = list(ip_map[ip].keys())[0]
            test_url = ip_map[ip][first_name]
            r = requests.get(test_url, timeout=TIMEOUT, stream=True, headers={"User-Agent":"Mozilla/5.0"})
            return ip, r.status_code == 200
        except: return ip, False

    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as exe:
        futures = {exe.submit(check, ip): ip for ip in all_ips}
        for f in concurrent.futures.as_completed(futures):
            processed += 1
            ip, ok = f.result()
            # è¿˜åŸæˆæ–‡ä»¶æ ¼å¼
            block_content = f"{ip},#genre#\n"
            for name, url in ip_map[ip].items():
                block_content += f"{name},{url}\n"
            block_content += "\n"
            
            if ok:
                revived.append(block_content)
                print(f"[{processed}/{total_ips}] âœ… [å­˜æ´»] {ip}", flush=True)
            else:
                dead.append(block_content)
                print(f"[{processed}/{total_ips}] ğŸ’€ [å¤±æ•ˆ] {ip}", flush=True)

    with open(MID_REVIVED, 'w', encoding='utf-8') as f: f.writelines(revived)
    with open(MID_DEAD, 'w', encoding='utf-8') as f: f.writelines(dead)
    print(f"ğŸ“Š æ¢æµ‹å®Œæˆã€‚å­˜æ´»: {len(revived)} | å¾…æŠ¢æ•‘: {len(dead)}", flush=True)

if __name__ == "__main__": main()
