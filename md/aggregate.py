import os, sys, requests, re, concurrent.futures
from urllib.parse import urlparse

# é…ç½®
INPUT_RAW = "tvbox_output.txt"
LOCAL_BASE = "md/aggregated_hotel.txt"
MID_REVIVED = "revived_temp.txt"
MID_DEAD = "dead_tasks.txt"
TIMEOUT = 3
MAX_WORKERS = 30

def is_valid_ip(ip_str):
    """æ ¡éªŒ IP:Port æˆ– åŸŸå:Port"""
    pattern = r'^(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(\.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+):[0-9]+$'
    return bool(re.match(pattern, ip_str))

def main():
    ip_map = {} # ç»“æ„: { "IP:Port": { "é¢‘é“å": "URL" } }

    def load_data(path, label):
        if not os.path.exists(path): return
        print(f"ğŸ“– æ­£åœ¨ä» [{label}] åŠ è½½åŸºå› ...", flush=True)
        with open(path, 'r', encoding='utf-8', errors='ignore') as f:
            cur_ip = None
            for line in f:
                line = line.strip()
                if not line: continue
                if "#genre#" in line:
                    potential_ip = line.split(',')[0].strip()
                    if is_valid_ip(potential_ip):
                        cur_ip = potential_ip
                        if cur_ip not in ip_map: ip_map[cur_ip] = {}
                    else: cur_ip = None
                    continue
                if ',' in line and cur_ip:
                    name, url = line.split(',', 1)
                    # å¦‚æœåº•åº“å·²å­˜åœ¨è¯¥é¢‘é“ï¼Œä¸è¦†ç›–ï¼Œä¿ç•™æ‰‹åŠ¨ä¿®æ”¹çš„ç»“æœ
                    if name.strip() not in ip_map[cur_ip]:
                        ip_map[cur_ip][name.strip()] = url.strip()

    # é‡ç‚¹ï¼šå…ˆåŠ è½½æœ¬åœ°åº•åº“ï¼ˆå«ä½ çš„æ‰‹åŠ¨ä¿®æ”¹ï¼‰ï¼Œå†åˆå¹¶æ–°æŠ“å–çš„æº
    load_data(LOCAL_BASE, "æœ¬åœ°åº•åº“")
    load_data(INPUT_RAW, "æ–°æŠ“å–æº")

    all_ips = list(ip_map.keys())
    total_ips = len(all_ips)
    print(f"ğŸ“¡ å…±æœ‰ {total_ips} ä¸ªæœ‰æ•ˆ IP ç½‘æ®µå‚ä¸æ¢æµ‹...", flush=True)

    revived, dead = [], []
    processed = 0

    def check(ip):
        try:
            # å–è¯¥ IP ä¸‹çš„ç¬¬ä¸€ä¸ªé¢‘é“æµ‹è¯•
            first_name = list(ip_map[ip].keys())[0]
            test_url = ip_map[ip][first_name]
            r = requests.get(test_url, timeout=TIMEOUT, stream=True, headers={"User-Agent":"Mozilla/5.0"})
            return ip, r.status_code == 200
        except: return ip, False

    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as exe:
        futures = {exe.submit(check, ip): ip for ip in all_ips}
        for f in concurrent.futures.as_completed(futures):
            processed += 1
            ip, ok = f.result()
            # è¿˜åŸæˆæ–‡ä»¶æ ¼å¼
            block_content = f"{ip},#genre#\n"
            for name, url in ip_map[ip].items():
                block_content += f"{name},{url}\n"
            block_content += "\n"
            
            if ok:
                revived.append(block_content)
                print(f"[{processed}/{total_ips}] âœ… [å­˜æ´»] {ip}", flush=True)
            else:
                dead.append(block_content)
                print(f"[{processed}/{total_ips}] ğŸ’€ [å¤±æ•ˆ] {ip}", flush=True)

    with open(MID_REVIVED, 'w', encoding='utf-8') as f: f.writelines(revived)
    with open(MID_DEAD, 'w', encoding='utf-8') as f: f.writelines(dead)
    print(f"ğŸ“Š æ¢æµ‹å®Œæˆã€‚å­˜æ´»: {len(revived)} | å¾…æŠ¢æ•‘: {len(dead)}", flush=True)

if __name__ == "__main__": main()
