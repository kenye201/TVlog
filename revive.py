import os
import re
import urllib.request
import threading
import time
from queue import Queue
from urllib.parse import urlparse, urlunparse
import sys

# --- é…ç½® ---
INPUT_FILE = "aggregated_hotel.txt"
OUTPUT_FILE = "revived_hotel.txt"
THREADS = 60  
TIMEOUT = 3

class ReviveScanner:
    def __init__(self):
        self.results = {}
        self.lock = threading.Lock()
        self.found_count = 0
        self.current_scanning_seg = ""

    def check_alive(self, url):
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) VLC/3.0.18"}
        try:
            req = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(req, timeout=TIMEOUT) as response:
                if response.getcode() in [200, 206]:
                    content = response.read(300).decode('utf-8', errors='ignore')
                    return "#EXTM3U" in content
        except:
            pass
        return False

    def worker(self, q):
        while not q.empty():
            task = q.get()
            c_seg, port, last_num, templates = task
            test_ip = f"{c_seg}.{last_num}"
            
            # æ‹¿åˆ°æ¢é’ˆé¢‘é“åå’Œå®Œæ•´URLæ¨¡å‹
            probe_name = list(templates.keys())[0]
            orig_url = templates[probe_name]
            
            # ç²¾å‡†æ‹¼æ¥
            p = urlparse(orig_url)
            new_netloc = f"{test_ip}:{port}"
            new_parts = list(p)
            new_parts[1] = new_netloc
            test_url = urlunparse(new_parts)

            if self.check_alive(test_url):
                with self.lock:
                    self.found_count += 1
                    self.results[test_ip] = {}
                    for name, old_url in templates.items():
                        op = urlparse(old_url)
                        ou = list(op)
                        ou[1] = new_netloc
                        self.results[test_ip][name] = urlunparse(ou)
                
                # å‘ç°æˆåŠŸï¼Œé«˜äº®æ˜¾ç¤º
                sys.stdout.write(f"\nâœ… [æˆåŠŸå¤æ´»] {test_ip}:{port} | é¢‘é“: {probe_name}\n")
                sys.stdout.flush()
            
            q.task_done()

def main():
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° {INPUT_FILE}"); return

    # è§£ææ®µåŸºå› 
    segments = []
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        current_templates = {}
        for line in f:
            line = line.strip()
            if not line: continue
            if "#genre#" in line:
                if current_templates:
                    first_url = next(iter(current_templates.values()))
                    p = urlparse(first_url)
                    c_seg = ".".join(p.netloc.split(':')[0].split('.')[:3])
                    port = p.netloc.split(':')[1] if ':' in p.netloc else "80"
                    segments.append({'c_seg': c_seg, 'port': port, 'tpl': current_templates.copy()})
                current_templates = {}
            elif ',' in line:
                name, url = line.split(',', 1)
                current_templates[name] = url

    print(f"ğŸš€ å¼€å§‹æ‰«æï¼Œå…± {len(segments)} ä¸ªåŸå§‹ IP æ®µå¾…å¤æ´»...")
    scanner = ReviveScanner()

    # æŒ‰ç»„é¡ºåºæ‰§è¡Œæ‰«æï¼Œä½†ç»„å†…ä½¿ç”¨å¤šçº¿ç¨‹å¹¶å‘
    for i, seg in enumerate(segments):
        c_seg = seg['c_seg']
        port = seg['port']
        tpl = seg['tpl']
        
        print(f"\nğŸ“¡ [{i+1}/{len(segments)}] æ­£åœ¨æ‰«æ C æ®µ: {c_seg}.0/24 (ç«¯å£: {port})")
        
        # ä¸ºå½“å‰æ®µå»ºç«‹é˜Ÿåˆ—
        q = Queue()
        for last_num in range(1, 255):
            q.put((c_seg, port, last_num, tpl))

        # å¯åŠ¨çº¿ç¨‹æ± å¤„ç†è¿™ 254 ä¸ª IP
        threads = []
        for _ in range(THREADS):
            t = threading.Thread(target=scanner.worker, args=(q,))
            t.daemon = True
            t.start()
            threads.append(t)

        # ç­‰å¾…è¿™ä¸€ç»„æ‰«å®Œå†æ‰«ä¸‹ä¸€ç»„ï¼Œæ–¹ä¾¿å‰å°è§‚å¯Ÿ
        while not q.empty():
            # ç®€å•çš„è¿›åº¦åé¦ˆ
            remaining = q.qsize()
            done = 254 - remaining
            percent = (done / 254) * 100
            sys.stdout.write(f"\r   è¿›åº¦: {percent:.1f}% | å·²å‘ç°: {scanner.found_count} ")
            sys.stdout.flush()
            time.sleep(0.5)
        
        q.join() # ç¡®ä¿çº¿ç¨‹æ”¶å°¾

    # ä¿å­˜ç»“æœ
    print(f"\n\nğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœåˆ° {OUTPUT_FILE}...")
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        for ip in sorted(scanner.results.keys()):
            chans = scanner.results[ip]
            netloc = urlparse(next(iter(chans.values()))).netloc
            f.write(f"{netloc},#genre#\n")
            for name in sorted(chans.keys(), key=lambda x: (not x.startswith("CCTV"), x)):
                f.write(f"{name},{chans[name]}\n")
            f.write("\n")

    print(f"âœ… æ‰«æç»“æŸï¼å…±å¤æ´» {scanner.found_count} ä¸ªæ–°æºã€‚")

if __name__ == "__main__":
    main()
